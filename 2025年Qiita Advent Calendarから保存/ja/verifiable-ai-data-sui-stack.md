---
title:  Sui Stack による検証可能なデータで、より良い AI を実現する [Sui Foundation Blog]
tags: SUI Blockchain AI AIエージェント Walrus
author: nft
slide: false
---
AI の未来は、よりスマートなモデルだけではありません。検証可能なデータこそが鍵であり、Sui Stack はそれを可能にする信頼のレイヤーを構築しています。

![Better AI Starts with Verifiable Data via The Sui Stack](https://blog.sui.io/content/images/size/w2000/2025/10/10-28-Blog-Header.png)

:::note
元記事: [Better AI Starts with Verifiable Data via The Sui Stack](https://blog.sui.io/verifiable-ai-data-sui-stack/)
:::

AI の採用は急速に進んでいますが、その基盤はまだ追いついていません。

すべてのモデル、すべてのチャットボット、そしてすべてのエージェントの背後には、一つのシンプルな依存関係があります。それはデータです。

そして、「ゴミを入れれば、ゴミが出る（garbage in, garbage out）」という言葉があるように、AI システムに供給されるデータが不完全であったり、改ざんされていたり、検証不可能であったりすれば、どれだけモデルをファインチューニングしても、出力を真に信頼できるものにすることはできません。今日のデータパイプラインの多くは、まさにそのような状態です。不透明で、可変であり、AI モデルがそれらを消費した後では監査することが不可能なのです。

この可視性の欠如は、単にコンプライアンスリスクを生み出すだけでなく、ユーザーにとってより悪い結果をもたらします。間違った事実を自信満々に引用するチャットボット、透明性のない予測を行う金融モデル、未検証の入力データで訓練された医療 AI などを考えてみてください。データがどこから来たのか、どのように変更されたのかを証明できない場合、信頼がボトルネックとなり、プロダクトの品質が低下します。

この問題を解決する時が来ました。

## 生データから検証可能なインテリジェンスへ

次世代の AI インフラストラクチャは、より大きな GPU やより高速な API だけではなく、検証可能なデータフローも重要になります。

そこで登場するのが Sui Stack です。AI ライフサイクルのすべてのステップにおいて、検証可能性、プライバシー、そしてコントロールを AI システムに独自に提供する、組み合わせ可能な基盤です。

インテリジェントシステムの信頼レイヤーと考えてください。各コンポーネントには明確な役割があります。

* [Walrus](https://walrus.xyz/?ref=blog.sui.io): AI 時代のデータマーケットを可能にする開発者プラットフォーム。業界全体のデータを信頼できる、証明可能、収益化可能、そして安全なものにします。
* [Seal](https://seal.mystenlabs.com/?ref=blog.sui.io): プログラマブルな暗号化とアクセス制御。誰が何を復号化できるか、どのくらいの期間、どのようなルールの下で、を定義します。
* [Nautilus](https://sui.io/nautilus?ref=blog.sui.io): 機密性と検証可能なコンピューティング。正確性の暗号学的証明を生成する信頼できるエンクレーブ内でモデル推論と AI エージェントを実行します。
* [Sui](https://sui.io/?ref=blog.sui.io): すべてをオンチェーンで結びつける調整とプロヴェナンス（来歴）レイヤー。アクセスルールを強制し、検証可能なレシートを記録します。

![](https://blog.sui.io/content/images/2025/10/Sui-AI-Stack.png)

検証可能な AI ワークフローの高レベルビュー: Walrus に保存されたデータが、Nautilus エンクレーブで処理され、Sui 上の Seal アクセスポリシーを通じて調整されます。

これらが一体となって Sui Stack を形成し、自律性、データ権利、そして透明性を尊重する AI システムを構築する新しい方法を提供します。

## ビルダーにとって重要な理由

AI システムを構築する開発者、特に機密性の高いデータや高価値データを扱う開発者にとって、今日のインフラストラクチャは不十分なことがよくあります。プロヴェナンスの確立は困難で、アクセス制御は扱いづらく、コンピュートは実質的にブラックボックスです。データは検証可能な痕跡を残さずに移動し、それが途中で改変されたかどうかを誰も判断できません。

この不確実性はイノベーションを遅らせ、信頼を損ないます。コントロールを維持するために、チームはしばしばクラウドサイロにデータを過度に集中させるか、あるいは協業の名の下に、完全に管理できないシステム間でデータを過剰に共有します。エージェント的なワークフローが正しく実行されているように見える場合でも、意図したとおりに実行されたという暗号学的証明はありません。

Sui Stack はこの摩擦を取り除きます。Walrus、Seal、Nautilus、そして Sui を組み合わせることで、ビルダーは検証可能な保証を持ってデータを保存、ゲート、そしてコンピュートする能力を得られます。開発者は小さく始めることができます。データセットを暗号化してアクセスルールを強制するか、モデルトレーニングジョブやエージェント推論の実行に検証可能な証明を追加するだけです。そこから、信頼が設計によって組み込まれた、組み合わせ可能で完全に監査可能なデータパイプラインへとスケールできます。

## エンドユーザーにとって重要な理由

エンドユーザーは、AI システムが提供する回答、推奨事項、および結果に対して信頼を持つ必要があります。モデルが検証不可能または不完全なデータセットで訓練されている場合、結果は誤解を招く可能性があります。

データパイプラインが検証不可能な場合、ユーザーはしばしば微妙ながら深刻な形で代償を払います。

* 信頼できない回答: 不完全または未検証のデータで訓練されたチャットボットやコパイロットは、自信に満ちた口調で話すものの、ユーザーを誤った方向に導く可能性があり、時には重要な状況においてもそうなります。
* 隠れたバイアス: トレーニングデータのソースが不透明な場合、システム的なバイアスを検出または修正することが不可能になり、不公正または危険な決定につながります。
* 説明責任の欠如: AI が生成した決定が誰かに影響を与える場合、例えばローンの承認、医学的診断、または推奨事項などにおいて、その決定がどのように行われたかを誰も追跡できない場合、信頼は崩壊する可能性があります。

検証可能なスタックは、このダイナミクスを変えます。

モデルが証明可能で、ポリシーが強制され、監査可能なデータで訓練され実行される場合、ユーザーはより一貫した回答、より明確な説明、そして信頼のためのより強固な基盤を得ることができます。これは「モデルがそう言っている」と「なぜそれを信頼できるかの理由がある」の違いです。

## 実際にはどのように見えるか

Sui と Walrus のエコシステム全体で、ビルダーはすでにこれらのアイデアを実践し、検証可能なデータの影響を示す方法で活用しています。

プライベート推論とエージェント的ワークフローを構築している人もいます。モデルは Walrus 上にホストされ、Seal で暗号化され、トークンゲーティングなどの厳格でプログラマブルな許可の下で、Nautilus エンクレーブを通してのみアクセスされます。他の人々は、企業向けのセキュアな分析環境をデプロイしており、すべてのクエリと埋め込み検索を説明責任を強化する監査可能なイベントに変えています。

コラボレーティブデータルームを通じて、別々のチームが暗号化されたデータを共有し、Nautilus エンクレーブ内で計算を実行でき、参加者はどのデータが使用され、どのように使用されたかを示す検証可能なレシートを受け取ります。一方、AI マーケットプレイスも登場しており、ビルダーはデータセット、モデル、またはエージェントを登録し、独自のライセンス条件を定義し、AI システムが直接アクセスできるようにしています。

これらのユースケースはすべて同じ基盤を共有しています。検証可能なデータ、プログラマブルなアクセス、そして Sui Stack によって実現される信頼できるコンピュートです。

## Walrus: AI 時代のデータバックボーン

このビジョンの中心には Walrus、データエコノミーのための開発者プラットフォームがあります。Walrus は単なる分散型ストレージではなく、世界のデータに対する信頼を固定します。Walrus 上のすべてのファイルとモデルには検証可能な ID が付与され、すべての更新は追跡可能かつ証明可能であり、すべてのデータセットを安全にライセンスまたは収益化できます。

リアルタイムデータを取得する AI エージェントから、監査可能な AI パイプラインを構築する企業まで、Walrus はデータを AI スタックにおける第一級市民にし、後付けではありません。

## 今後の展開

これはほんの始まりに過ぎません。今後数週間にわたり、ビルダーがすでにこれらのプリミティブを新しい方法で使用している様子を探求します。証明とポリシーでモデルトレーニングと推論パイプラインをラップすること、プレミアムデータと AI モデルのプログラマティックなライセンシングを作成すること、そして検証可能でプライバシーを保護する支払いを通じてインテリジェントシステムがトランザクションを実行できるようにすることなどです。

これらはすべて同じ基盤の上に構築されています。検証可能なデータです。

なぜなら、AI の未来は単にスマートなだけではなく、証明可能なものになるからです。
